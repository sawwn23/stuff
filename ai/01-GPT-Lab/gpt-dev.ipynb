{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79595c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self attention from scratch using PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90506e1",
   "metadata": {},
   "source": [
    "The attention mechanism, often called the \"attention node\" or layer in Transformers, lets the model focus on relevant parts of the input sequence, like words in a sentence, instead of treating them equally. It replaces older sequential processing in models like RNNs, enabling faster parallel computation and better handling of long-range dependencies. This core idea from the 2017 \"Attention is All You Need\" paper powers models like GPT and BERT. [youtube](https://www.youtube.com/watch?v=KMHkbXzHn7s)\n",
    "\n",
    "## Core Idea\n",
    "Imagine reading a sentence: \"The cat, which sat on the mat, ran away.\" When understanding \"ran,\" the model needs to know it refers to the cat, not the mat. Attention scores how much each word (like \"cat\") relates to others (like \"ran\"), weighting their influence dynamically. [sciencedirect](https://www.sciencedirect.com/topics/computer-science/self-attention-mechanism)\n",
    "\n",
    "## Query, Key, Value\n",
    "Each input word turns into three vectors: Query (what I'm looking for), Key (what others offer), and Value (the actual info). For a word's query, it compares to all keys via dot product to get raw scores, then scales them (divide by sqrt of key size) to stabilize training. [youtube](https://www.youtube.com/watch?v=KMHkbXzHn7s)\n",
    "\n",
    "## Computing Attention\n",
    "Softmax turns scores into probabilities (weights summing to 1), then multiplies by values for a weighted output mix. This creates context-rich representations where important distant words contribute more. [geeksforgeeks](https://www.geeksforgeeks.org/nlp/transformer-attention-mechanism-in-nlp/)\n",
    "\n",
    "## Multi-Head Attention\n",
    "Instead of one attention pass, split into multiple \"heads\" (e.g., 8-16), each learning different relationships‚Äîlike syntax in one head, semantics in another. Outputs concatenate and project linearly for richer context. [youtube](https://www.youtube.com/watch?v=BvZS6PDUtD4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c43fbac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87221d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 32])\n",
      "tensor([[[ 1.8077e-01, -6.9988e-02, -3.5962e-01, -9.1520e-01,  6.2577e-01,\n",
      "           2.5510e-02,  9.5451e-01,  6.4349e-02,  3.6115e-01,  1.1679e+00,\n",
      "          -1.3499e+00, -5.1018e-01,  2.3596e-01, -2.3978e-01, -9.2111e-01,\n",
      "           1.5433e+00,  1.3488e+00, -1.3964e-01,  2.8580e-01,  9.6512e-01,\n",
      "          -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01,  1.2603e-01,\n",
      "          -1.5627e+00, -1.1601e+00, -3.3484e-01,  4.4777e-01, -8.0164e-01,\n",
      "           1.5236e+00,  2.5086e+00],\n",
      "         [-6.6310e-01, -2.5128e-01,  1.0101e+00,  1.2155e-01,  1.5840e-01,\n",
      "           1.1340e+00, -1.1539e+00, -2.9840e-01, -5.0754e-01, -9.2392e-01,\n",
      "           5.4671e-01, -1.4948e+00, -1.2057e+00,  5.7182e-01, -5.9735e-01,\n",
      "          -6.9368e-01,  1.6455e+00, -8.0299e-01,  1.3514e+00, -2.7592e-01,\n",
      "          -1.5108e+00,  2.1048e+00,  2.7630e+00, -1.7465e+00,  1.4516e+00,\n",
      "          -1.5103e+00,  8.2115e-01, -2.1153e-01,  7.7890e-01,  1.5333e+00,\n",
      "           1.6097e+00, -4.0323e-01],\n",
      "         [-8.3447e-01,  5.9780e-01, -5.1406e-02, -6.4559e-02, -4.9701e-01,\n",
      "           4.6576e-01, -2.5726e-01, -1.0673e+00,  2.0089e+00, -5.3698e-01,\n",
      "           2.2280e-01,  6.9705e-01, -1.4267e+00,  9.0594e-01,  1.4459e-01,\n",
      "           2.2800e-01,  2.4900e+00, -1.2237e+00,  1.0107e+00,  5.5600e-01,\n",
      "          -1.5935e+00, -1.2706e+00,  6.9033e-01, -1.9614e-01,  3.4491e-01,\n",
      "          -3.4189e-01,  4.7587e-01, -7.6634e-01, -4.1896e-01, -4.3699e-01,\n",
      "          -1.0012e+00, -4.0943e-01],\n",
      "         [-1.6669e+00, -1.3651e+00, -1.6552e-01,  9.6225e-01,  3.1549e-02,\n",
      "          -7.4190e-01, -2.9779e-01,  1.7166e-02, -1.7722e-01, -1.3343e-01,\n",
      "           2.9396e-01,  1.3850e+00,  1.2091e-01,  2.5418e+00, -6.4046e-01,\n",
      "          -1.9740e+00, -3.2957e-01,  7.9589e-03,  9.2623e-01, -1.8846e+00,\n",
      "           1.6696e-01,  4.5862e-01, -1.7662e+00,  5.8599e-01,  1.7510e+00,\n",
      "           2.8072e-01,  3.1096e-01, -6.5376e-01, -6.5763e-01,  3.1845e-01,\n",
      "          -5.4959e-01, -1.4649e+00],\n",
      "         [-2.0555e+00,  1.8275e+00,  1.3035e+00, -4.5013e-01,  1.3471e+00,\n",
      "           1.6910e+00, -1.2445e-01, -1.6824e+00, -2.6608e-02,  7.4049e-02,\n",
      "           1.0517e+00,  6.7789e-01,  3.0665e-01, -7.4723e-01,  7.4349e-01,\n",
      "           8.8766e-01,  2.2874e+00,  9.6114e-01, -1.5297e+00, -2.9122e-01,\n",
      "          -1.1395e-01, -3.1367e-01, -6.2931e-01,  1.1385e+00, -9.9127e-01,\n",
      "           1.6999e-01,  1.2249e+00, -2.3454e-01, -1.0572e+00, -6.5427e-01,\n",
      "           1.5909e+00, -6.9949e-01],\n",
      "         [-8.9606e-01,  6.6191e-02, -5.6280e-02,  2.3412e+00, -2.7234e+00,\n",
      "           5.0967e-01, -8.1447e-01, -2.4604e-01,  4.5085e-03,  2.0474e+00,\n",
      "          -1.5755e-01, -2.1867e-01, -1.3519e+00, -5.7281e-02, -1.8540e+00,\n",
      "          -1.3849e+00, -3.4540e-01, -1.1625e+00,  1.4448e-01,  1.6632e-01,\n",
      "           7.5070e-01,  9.1317e-01, -1.7277e+00,  1.3055e+00,  9.5932e-01,\n",
      "           1.0600e+00,  6.2986e-01, -1.2867e+00, -6.8748e-01,  2.1382e+00,\n",
      "           5.1141e-01,  1.2191e+00],\n",
      "         [ 1.9098e-01, -3.4251e-01,  1.7955e+00,  1.3915e+00,  1.0785e+00,\n",
      "          -6.1495e-01, -4.5885e-01,  5.6748e-01,  1.8289e-02, -1.6608e+00,\n",
      "           1.1169e+00,  5.1965e-01, -1.2423e+00, -9.6182e-01, -8.4998e-02,\n",
      "           1.1854e-01,  2.9843e-01, -7.2636e-01, -3.1187e-01, -4.5604e-01,\n",
      "           6.4407e-01,  6.0728e-01,  1.2397e+00,  7.3249e-01,  5.0418e-01,\n",
      "           8.7135e-01, -2.7416e-01, -7.4689e-01, -5.8324e-01,  3.6988e-01,\n",
      "          -5.5563e-01, -3.9828e-01],\n",
      "         [-5.8188e-01, -2.2083e-01,  1.3537e-02, -3.0574e-01, -3.0384e-02,\n",
      "           8.2161e-01,  3.8670e-04, -4.4742e-01,  8.2040e-01, -1.5178e+00,\n",
      "           6.1587e-01, -1.8648e+00, -9.7773e-01,  6.3224e-02, -4.5483e-01,\n",
      "          -4.1474e-01,  1.4987e+00, -3.9867e-02, -8.0510e-01, -1.1624e+00,\n",
      "           4.2716e-01, -2.8192e-01, -1.2773e-02, -8.7792e-01, -3.2248e-01,\n",
      "           1.8299e-01, -9.3030e-01, -1.2488e+00,  1.1192e+00, -1.9079e+00,\n",
      "          -5.2756e-01,  1.0807e+00]]])\n",
      "torch.Size([4, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)  # (batch, time, channels)\n",
    "print(x.shape)\n",
    "print(x[:1])\n",
    "\n",
    "## signle head self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B,T,head_size)\n",
    "q = query(x)  # (B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1)  # (B,T,head_size) @ (B,head_size,T) --> (B,T,T)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = torch.softmax(wei, dim=-1)\n",
    "out = wei @ x  # (T,T) @ (B,T,C) --> (B,T,C)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9ec098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41dc38",
   "metadata": {},
   "source": [
    "## Understanding Q, K, V - Simple Version\n",
    "\n",
    "### Think of it Like a Library Search\n",
    "\n",
    "Imagine you're in a library looking for books about \"cats\":\n",
    "\n",
    "- **Query (Q)**: The question you ask the librarian: *\"I want books about cats\"*\n",
    "- **Key (K)**: Labels on each book that describe what it's about: *\"This book is about cats\", \"This book is about dogs\", etc.*\n",
    "- **Value (V)**: The actual content inside each book\n",
    "\n",
    "### How Attention Works in 3 Steps\n",
    "\n",
    "**Step 1: Compare (Q @ K)**\n",
    "```\n",
    "Your query \"cats\" matches against all book labels:\n",
    "- Book 0 (about dogs): No match ‚Üí low score\n",
    "- Book 3 (about animals): Medium match ‚Üí medium score  \n",
    "- Book 6 (about cats): Perfect match ‚Üí HIGH score\n",
    "- Book 7 (about pets): Good match ‚Üí HIGH score\n",
    "```\n",
    "\n",
    "**Step 2: Normalize (softmax)**\n",
    "Convert scores into percentages that add up to 100%:\n",
    "```\n",
    "Book 0: 2.1%\n",
    "Book 3: 22.97%\n",
    "Book 6: 24.23%  ‚Üê Most relevant\n",
    "Book 7: 23.91%  ‚Üê Very relevant\n",
    "Others: ~9%\n",
    "```\n",
    "\n",
    "**Step 3: Get Information (weights @ V)**\n",
    "Take the content from each book, weighted by relevance:\n",
    "```\n",
    "Final result = 2.1% of book 0's content \n",
    "             + 22.97% of book 3's content\n",
    "             + 24.23% of book 6's content  ‚Üê gets most weight\n",
    "             + 23.91% of book 7's content\n",
    "             + ...\n",
    "```\n",
    "\n",
    "### Real Example from Your Code\n",
    "\n",
    "Your attention weights: `[0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]`\n",
    "\n",
    "This says: *\"Position 6 is most relevant (24.23%), position 7 is very relevant (23.91%), position 3 is relevant (22.97%), but position 0 is barely relevant (2.1%)\"*\n",
    "\n",
    "### Why Are Some Values High and Others Low?\n",
    "\n",
    "- **High (0.24, 0.23, 0.22)** = These tokens are similar in meaning\n",
    "  - They contain information the current token needs\n",
    "  - The model learned they're related\n",
    "\n",
    "- **Low (0.021, 0.055)** = These tokens are different  \n",
    "  - They don't help predict the next word\n",
    "  - Not worth focusing on\n",
    "\n",
    "### The Key Insight\n",
    "\n",
    "Self-attention is like asking: *\"Which previous words matter for understanding THIS word?\"*\n",
    "\n",
    "High attention weight ‚Üí \"This word is very important for me\"\n",
    "Low attention weight ‚Üí \"This word doesn't help me\"\n",
    "\n",
    "**That's how transformers understand context and relationships!** üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9344969",
   "metadata": {},
   "source": [
    "- Attention is a communication mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53754c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
